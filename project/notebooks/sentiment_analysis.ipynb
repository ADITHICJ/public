{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Service Feedback Analyzer - Sentiment Analysis with Naive Bayes\n",
    "\n",
    "This notebook demonstrates how to use Naive Bayes for sentiment analysis of public service feedback. We'll cover:\n",
    "\n",
    "1. Data preparation\n",
    "2. Feature extraction\n",
    "3. Training a Naive Bayes classifier\n",
    "4. Evaluating the model\n",
    "5. Classifying new feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample Data Creation\n",
    "\n",
    "For this demonstration, we'll create a sample dataset of public service feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV\n",
    "df = pd.read_csv('sentiment_analysis.csv')\n",
    "\n",
    "# Step 2: Keep only required columns\n",
    "df = df[['feedback', 'Sentiment']]\n",
    "\n",
    "# Step 3: Rename 'Sentiment' to 'sentiment'\n",
    "df.rename(columns={'Sentiment': 'sentiment'}, inplace=True)\n",
    "\n",
    "# Step 4: Map sentiment numbers to text labels\n",
    "df['sentiment_label'] = df['sentiment'].map({0: 'negative', 1: 'neutral', 2: 'positive', 3: 'urgent'})\n",
    "\n",
    "# (Optional) Check if it worked\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiment_label', data=df)\n",
    "plt.title('Distribution of Sentiment Classes')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "Before training our model, we need to preprocess the text data. This involves:\n",
    "- Converting to lowercase\n",
    "- Removing special characters\n",
    "- Removing stopwords\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the feedback column\n",
    "df['processed_feedback'] = df['feedback'].apply(preprocess_text)\n",
    "\n",
    "# Display examples of processed text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df[['feedback', 'processed_feedback', 'sentiment_label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "Next, we'll convert the text data into numerical features using the Bag of Words model and TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['processed_feedback'], \n",
    "    df['sentiment'], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['sentiment']  # Ensure balanced classes in train and test sets\n",
    ")\n",
    "\n",
    "# Initialize the vectorizers\n",
    "count_vectorizer = CountVectorizer(max_features=1000)  # Limit features to avoid overfitting\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transform the data\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Display feature information\n",
    "print(f\"Number of features (Count Vectorizer): {X_train_counts.shape[1]}\")\n",
    "print(f\"Number of features (TF-IDF Vectorizer): {X_train_tfidf.shape[1]}\")\n",
    "\n",
    "# Get feature names for later analysis\n",
    "feature_names = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Naive Bayes Classifier\n",
    "\n",
    "We'll train two separate models - one using Bag of Words (Count Vectorizer) and one using TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Multinomial Naive Bayes classifiers\n",
    "nb_counts = MultinomialNB()\n",
    "nb_tfidf = MultinomialNB()\n",
    "\n",
    "# Train models\n",
    "nb_counts.fit(X_train_counts, y_train)\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_counts = nb_counts.predict(X_test_counts)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate probability predictions for later analysis\n",
    "y_prob_counts = nb_counts.predict_proba(X_test_counts)\n",
    "y_prob_tfidf = nb_tfidf.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Let's evaluate the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Count Vectorizer model\n",
    "print(\"Model: Naive Bayes with Bag of Words\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_counts):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_counts, \n",
    "                           target_names=['Negative', 'Neutral', 'Positive', 'Urgent']))\n",
    "\n",
    "# Confusion Matrix for Count Vectorizer model\n",
    "cm_counts = confusion_matrix(y_test, y_pred_counts)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_counts, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Neutral', 'Positive', 'Urgent'],\n",
    "            yticklabels=['Negative', 'Neutral', 'Positive', 'Urgent'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Naive Bayes with Bag of Words')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate TF-IDF model\n",
    "print(\"\\nModel: Naive Bayes with TF-IDF\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tfidf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, \n",
    "                           target_names=['Negative', 'Neutral', 'Positive', 'Urgent']))\n",
    "\n",
    "# Confusion Matrix for TF-IDF model\n",
    "cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tfidf, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Neutral', 'Positive', 'Urgent'],\n",
    "            yticklabels=['Negative', 'Neutral', 'Positive', 'Urgent'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Naive Bayes with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which words are most predictive for each sentiment class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(classifier, feature_names, class_labels, n=10):\n",
    "    \"\"\"Display top n features for each class\"\"\"\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        print(f\"\\nTop {n} features for class: {class_label}\")\n",
    "        \n",
    "        # Get feature log probabilities for the class\n",
    "        feature_log_probs = classifier.feature_log_prob_[i]\n",
    "        \n",
    "        # Get indices of top features\n",
    "        top_indices = np.argsort(feature_log_probs)[::-1][:n]\n",
    "        \n",
    "        # Print top features\n",
    "        for idx in top_indices:\n",
    "            print(f\"{feature_names[idx]}: {np.exp(feature_log_probs[idx]):.4f}\")\n",
    "\n",
    "# Class labels\n",
    "class_labels = ['Negative', 'Neutral', 'Positive', 'Urgent']\n",
    "\n",
    "# Display top features for the TF-IDF model\n",
    "print(\"Top features by class (TF-IDF Model):\")\n",
    "show_top_features(nb_tfidf, tfidf_vectorizer.get_feature_names_out(), class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Building a Complete Sentiment Analysis Function\n",
    "\n",
    "Now that we've trained and evaluated our model, let's create a function to analyze new feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, model=nb_tfidf, vectorizer=tfidf_vectorizer):\n",
    "    \"\"\"Analyze the sentiment of a text input\"\"\"\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Vectorize the text\n",
    "    text_vector = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Predict sentiment class\n",
    "    sentiment_class = model.predict(text_vector)[0]\n",
    "    \n",
    "    # Get probability scores\n",
    "    proba = model.predict_proba(text_vector)[0]\n",
    "    \n",
    "    # Map numeric label to text label\n",
    "    sentiment_map = {0: 'negative', 1: 'neutral', 2: 'positive', 3: 'urgent'}\n",
    "    sentiment = sentiment_map[sentiment_class]\n",
    "    \n",
    "    # Calculate confidence score (max probability)\n",
    "    confidence = max(proba)\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'sentiment': sentiment,\n",
    "        'confidence': confidence,\n",
    "        'probabilities': {\n",
    "            'negative': proba[0],\n",
    "            'neutral': proba[1],\n",
    "            'positive': proba[2],\n",
    "            'urgent': proba[3]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test the function with some sample feedback\n",
    "sample_feedback = [\n",
    "    \"The city's new recycling program is well organized and easy to use.\",\n",
    "    \"I've been trying to get a building permit for months and keep getting the runaround.\",\n",
    "    \"I'd like to know when the next city council meeting is scheduled.\",\n",
    "    \"There's a large pothole on Oak Street that's causing cars to swerve dangerously into oncoming traffic!\"\n",
    "]\n",
    "\n",
    "for feedback in sample_feedback:\n",
    "    result = analyze_sentiment(feedback)\n",
    "    print(f\"\\nText: {result['text']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "    print(\"Probability Distribution:\")\n",
    "    for sentiment, prob in result['probabilities'].items():\n",
    "        print(f\"  {sentiment}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Saving the Model\n",
    "\n",
    "Finally, let's save our trained model and vectorizer for use in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model and vectorizer\n",
    "with open('sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_tfidf, f)\n",
    "    \n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've built a Naive Bayes classifier for sentiment analysis of public service feedback. The model can categorize feedback into four classes: positive, negative, neutral, and urgent.\n",
    "\n",
    "Key takeaways:\n",
    "1. Naive Bayes is an effective algorithm for text classification tasks\n",
    "2. TF-IDF vectorization slightly outperformed the simpler Bag of Words approach\n",
    "3. The model shows good ability to distinguish between different sentiment classes\n",
    "4. Urgent feedback, which requires immediate attention, is successfully identified\n",
    "\n",
    "For a production system, you would want to:\n",
    "1. Train on a much larger dataset\n",
    "2. Consider more advanced models such as BERT or other transformer-based models\n",
    "3. Implement additional features like entity recognition to identify specific issues\n",
    "4. Continuously update the model as new feedback is collected\n",
    "\n",
    "This model provides a solid foundation for a public service feedback analyzer system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
